# -*- coding: utf-8 -*-
"""Predicitve_Analytic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12KNT2UgjD3sqc2OJw9zEt4H2RBTEmT0x

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

from sklearn.ensemble import RandomForestClassifier

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

"""# Load Dataset

Menampilkan dataset yang akan digunakan pada proyek ini
"""

df = pd.read_csv('/content/diabetes.csv')
df.head()

"""Di sini meanampilkan 5 baris pertama dari dataset

# Data Understanding
"""

# Cek struktur data
df.info()

"""Menampilkan jumlah baris, jumlah kolom, nama kolom, jumlah non-null pada tiap kolom, tipe data masing-masing kolom, dan penggunaan memori."""

# Statistik deskriptif
df.describe()

"""Menghasilkan nilai count, mean, std (standar deviasi), min, 25%, 50% (median), 75%, dan max untuk setiap kolom numerik."""

# Cek missing value
df.isnull().sum()

"""Menampilkan total nilai null di tiap kolom. Sangat berguna untuk mengecek data yang perlu dibersihkan.

Hasil: Tidak ditemukan missing value dalam dataset ini
"""

# Cek data duplicate
df.duplicated().sum()

"""Ini bertujuan untuk menghasilkan boolean series untuk baris duplikat, dan .sum() akan menghitung jumlah True (baris duplikat).

Hasil: Tidak ditemukan data duplicate dalam dataset ini

# Exploratory Data Analysis (EDA)
"""

# Distribusi target
sns.countplot(x='Outcome', data=df)
plt.title("Distribusi Pasien Diabetes")

"""Jumlah pasien yang tidak menderita diabetes (Outcome = 0) jauh lebih banyak, sekitar 500 orang, dibandingkan pasien yang menderita diabetes (Outcome = 1) yang berjumlah sekitar 260 orang."""

# Visualisasi distribusi tiap fitur
df.hist(figsize=(12, 10))
plt.suptitle('Distribusi Fitur-fitur dalam Dataset')
plt.show()

"""Grafik di atas menampilkan histogram distribusi untuk setiap fitur dalam dataset diabetes. Terlihat bahwa sebagian besar fitur memiliki distribusi yang tidak simetris atau condong ke satu sisi (skewed)."""

# Cek korelasi antar fitur
correlation_matrix = df.corr()
plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Heatmap Korelasi Antar Fitur')
plt.show()

"""Grafik di atas merupakan heatmap korelasi antar fitur dalam dataset diabetes. Korelasi ditunjukkan dalam rentang -1 hingga 1, di mana nilai mendekati 1 menunjukkan korelasi positif kuat, mendekati -1 menunjukkan korelasi negatif kuat, dan nilai mendekati 0 menunjukkan tidak ada korelasi linear yang signifikan."""

# Cek distribusi dari beberapa fitur terkait outcome
sns.pairplot(df, hue='Outcome', vars=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age'])
plt.suptitle('Pairplot Fitur terhadap Outcome')
plt.show()

"""Grafik di atas merupakan pairplot yang menggambarkan hubungan antar fitur dalam dataset diabetes berdasarkan nilai Outcome (0 = tidak diabetes, 1 = diabetes). Setiap titik mewakili satu pasien, dengan warna biru untuk Outcome 0 dan oranye untuk Outcome 1."""

# Cek hubungan antara dua fitur (BMI dan Glukosa)
sns.scatterplot(x='BMI', y='Glucose', hue='Outcome', data=df)
plt.title('Hubungan BMI vs Glukosa')
plt.show()

"""Grafik tersebut merupakan scatter plot yang menunjukkan hubungan antara dua fitur penting dalam dataset, yaitu BMI (Body Mass Index) dan Glukosa, dengan pewarnaan berdasarkan Outcome (0 = tidak diabetes, 1 = diabetes).

# Data Preparation
"""

# Pisahkan fitur dan label
X = df.drop('Outcome', axis=1)
y = df['Outcome']

"""Kode ini digunakan untuk memisahkan fitur (X) dan target/label (y) dari dataset. Kolom 'Outcome' dianggap sebagai target yang ingin diprediksi, sehingga dihapus dari DataFrame untuk membentuk X (fitur), sementara y menyimpan nilai 'Outcome' sebagai variabel yang akan dipelajari oleh model."""

# Normalisasi fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""Kode ini bertujuan untuk menstandardisasi fitur dalam X menggunakan StandardScaler dari scikit-learn. Standardisasi mengubah setiap fitur agar memiliki mean 0 dan standar deviasi 1, yang penting agar algoritma machine learning (terutama yang berbasis jarak seperti KNN atau gradient descent) bekerja optimal tanpa bias akibat skala yang berbeda-beda."""

# Split data: train, val, test
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

print(f"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")

"""Kode ini membagi data menjadi tiga bagian: 70% untuk pelatihan, dan sisanya dibagi rata untuk validasi dan pengujian. Stratify menjaga proporsi kelas tetap seimbang agar evaluasi model lebih akurat dan adil.

# Modeling

### Neural Network
"""

model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)

"""Kode ini digunakan untuk membangun, mengompilasi, dan melatih model neural network menggunakan Keras. Model terdiri dari dua hidden layer dengan aktivasi ReLU dan satu output layer dengan aktivasi sigmoid untuk klasifikasi biner. Fungsi loss yang digunakan adalah binary_crossentropy, sedangkan optimizer-nya adalah Adam."""

# Plot Akurasi
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title("Model Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("Model Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.tight_layout()
plt.show()

"""Kode ini bertujuan memvisualisasikan performa model selama pelatihan dengan menampilkan grafik akurasi dan loss untuk data pelatihan dan validasi. Visualisasi ini membantu mengevaluasi apakah model mengalami overfitting, underfitting, atau belajar secara optimal selama proses training.

### Random Forest
"""

# Inisialisasi model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

"""Membuat model Random Forest dengan 100 pohon dan seed tetap (random_state=42) untuk klasifikasi yang stabil dan akurat."""

# Latih model
rf_model.fit(X_train, y_train)

"""Melatih model menggunakan data training agar dapat mengenali pola antara fitur dan target."""

# Prediksi pada data test
rf_pred = rf_model.predict(X_test)
rf_proba = rf_model.predict_proba(X_test)[:, 1]

"""Memprediksi kelas dan probabilitas pada data uji; rf_pred menghasilkan label, rf_proba memberi skor probabilitas untuk evaluasi lebih lanjut.

# Evaluasi Model

### Neural Network
"""

# Evaluasi di data test
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Akurasi Test: {accuracy:.2f}")

"""Kode ini mengevaluasi performa model neural network pada data uji menggunakan metrik loss dan akurasi. Tujuannya adalah untuk mengetahui seberapa baik model mampu mengeneralisasi terhadap data yang belum pernah dilihat."""

# Prediksi MLP
y_pred_proba = model.predict(X_test)
y_pred_classes = (y_pred_proba > 0.5).astype("int32")

# AUC dengan probabilitas
mlp_auc = roc_auc_score(y_test, y_pred_proba)

"""Bagian ini menghasilkan prediksi probabilitas dan kelas dari model MLP pada data uji. Probabilitas digunakan untuk menghitung nilai AUC (Area Under Curve), yang menunjukkan kemampuan model membedakan antara kelas positif dan negatif."""

# Metrics MLP
print(confusion_matrix(y_test, y_pred_classes))
print("\n ------------------------------------------------------------")
print(classification_report(y_test, y_pred_classes))
print("ROC AUC MLP:", mlp_auc)

"""Kode ini menampilkan evaluasi model MLP dengan confusion matrix, classification report (presisi, recall, f1-score), dan nilai AUC. Tujuannya adalah memberikan gambaran menyeluruh tentang performa klasifikasi model neural network.

### Random Forest
"""

print("=== Evaluasi Model Random Forest ===")
print("Akurasi:", accuracy_score(y_test, rf_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, rf_pred))
print("Classification Report:\n", classification_report(y_test, rf_pred))
print("ROC AUC:", roc_auc_score(y_test, rf_proba))

"""Bagian ini melakukan evaluasi menyeluruh terhadap model Random Forest dengan mengukur akurasi, confusion matrix, classification report, dan nilai AUC untuk menilai performa klasifikasinya pada data uji."""

# === Perbandingan Hasil ===

mlp_accuracy = accuracy_score(y_test, y_pred_classes)
mlp_auc = roc_auc_score(y_test, y_pred_proba)

rf_accuracy = accuracy_score(y_test, rf_pred)
rf_auc = roc_auc_score(y_test, rf_proba)

print("=== Perbandingan Model ===")
print(f"MLP (Neural Network) - Akurasi: {mlp_accuracy:.2f}, AUC: {mlp_auc:.2f}")
print(f"Random Forest         - Akurasi: {rf_accuracy:.2f}, AUC: {rf_auc:.2f}")

"""Kode ini membandingkan kinerja dua model (MLP dan Random Forest) berdasarkan akurasi dan AUC. Tujuannya adalah menentukan model mana yang memberikan hasil prediksi lebih baik terhadap data uji."""